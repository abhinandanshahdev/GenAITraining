{
  "cells": [
    {
      "cell_type": "raw",
      "id": "1302a608-4b4d-46bf-bd0c-b4f13eff2e5e",
      "metadata": {
        "id": "1302a608-4b4d-46bf-bd0c-b4f13eff2e5e"
      },
      "source": [
        "---\n",
        "sidebar-position: 1\n",
        "title: Synthetic data generation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa3571cc",
      "metadata": {
        "id": "aa3571cc"
      },
      "source": [
        "\n",
        "## Use case - this is an adaptation from Langchain example notebook\n",
        "\n",
        "Synthetic data is artificially generated data, rather than data collected from real-world events. It's used to simulate real data without compromising privacy or encountering real-world limitations.\n",
        "\n",
        "Benefits of Synthetic Data:\n",
        "\n",
        "1. **Privacy and Security**: No real personal data at risk of breaches.\n",
        "2. **Data Augmentation**: Expands datasets for machine learning.\n",
        "3. **Flexibility**: Create specific or rare scenarios.\n",
        "4. **Cost-effective**: Often cheaper than real-world data collection.\n",
        "5. **Regulatory Compliance**: Helps navigate strict data protection laws.\n",
        "6. **Model Robustness**: Can lead to better generalizing AI models.\n",
        "7. **Rapid Prototyping**: Enables quick testing without real data.\n",
        "8. **Controlled Experimentation**: Simulate specific conditions.\n",
        "9. **Access to Data**: Alternative when real data isn't available.\n",
        "\n",
        "Note: Despite the benefits, synthetic data should be used carefully, as it may not always capture real-world complexities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca57012",
      "metadata": {
        "id": "bca57012"
      },
      "source": [
        "### Setup\n",
        "First, you'll need to have the langchain library installed, along with its dependencies. Since we're using the OpenAI generator chain, we'll install that as well. Since this is an experimental lib, we'll need to include `langchain_experimental` in our installs. We'll then import the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0377478",
      "metadata": {
        "id": "a0377478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef79da7-66f7-4159-c3da-452ce6c22f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.349-py3-none-any.whl (808 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.6/808.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.46-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.3.8-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_community-0.0.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.1,>=0.0.13 (from langchain)\n",
            "  Downloading langchain_core-0.0.13-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.13->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, langsmith, jsonpatch, httpcore, langchain-core, httpx, dataclasses-json, openai, langchain-community, langchain, langchain_experimental\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.349 langchain-community-0.0.1 langchain-core-0.0.13 langchain_experimental-0.0.46 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.8 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain_experimental openai\n",
        "# Set env var OPENAI_API_KEY or load from a .env file:\n",
        "# import dotenv\n",
        "# dotenv.load_dotenv()\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "from langchain_experimental.tabular_synthetic_data.openai import (\n",
        "    OPENAI_TEMPLATE,\n",
        "    create_openai_data_generator,\n",
        ")\n",
        "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
        "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
        "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a0917b",
      "metadata": {
        "id": "a5a0917b"
      },
      "source": [
        "## 1. Define Your Data Model\n",
        "Every dataset has a structure or a \"schema\". The MedicalBilling class below serves as our schema for the synthetic data. By defining this, we're informing our synthetic data generator about the shape and nature of data we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291bad6e",
      "metadata": {
        "id": "291bad6e"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BankingProductPropensity(BaseModel):\n",
        "    customer_id: int\n",
        "    customer_name: str\n",
        "    age: int\n",
        "    employment_status: str\n",
        "    annual_income: float\n",
        "    credit_score: int\n",
        "    existing_products: list[str]\n",
        "    product_interest: str  # This could be the banking product the customer is likely interested in\n",
        "    propensity_score: float  # A score indicating the likelihood of the customer being interested in the product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2059ca63",
      "metadata": {
        "id": "2059ca63"
      },
      "source": [
        "For instance, every record will have a `patient_id` that's an integer, a `patient_name` that's a string, and so on.\n",
        "\n",
        "## 2. Sample Data\n",
        "To guide the synthetic data generator, it's useful to provide it with a few real-world-like examples. These examples serve as a \"seed\" - they're representative of the kind of data you want, and the generator will use them to create more data that looks similar.\n",
        "\n",
        "Here are some fictional medical billing records:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b989b792",
      "metadata": {
        "id": "b989b792"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"example\": \"\"\"Customer ID: 101234, Customer Name: Alex Johnson, Age: 35, Employment Status: Employed,\n",
        "        Annual Income: 85000, Credit Score: 720, Existing Products: ['Savings Account', 'Credit Card'],\n",
        "        Product Interest: 'Mortgage', Propensity Score: 0.75\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"example\": \"\"\"Customer ID: 102345, Customer Name: Maria Garcia, Age: 28, Employment Status: Self-Employed,\n",
        "        Annual Income: 67000, Credit Score: 680, Existing Products: ['Checking Account'],\n",
        "        Product Interest: 'Personal Loan', Propensity Score: 0.65\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"example\": \"\"\"Customer ID: 103456, Customer Name: David Smith, Age: 40, Employment Status: Unemployed,\n",
        "        Annual Income: 32000, Credit Score: 590, Existing Products: ['Credit Card', 'Auto Loan'],\n",
        "        Product Interest: 'Credit Card Upgrade', Propensity Score: 0.55\"\"\"\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e28809",
      "metadata": {
        "id": "57e28809"
      },
      "source": [
        "## 3. Craft a Prompt Template\n",
        "The generator doesn't magically know how to create our data; we need to guide it. We do this by creating a prompt template. This template helps instruct the underlying language model on how to produce synthetic data in the desired format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6e042e",
      "metadata": {
        "id": "ea6e042e"
      },
      "outputs": [],
      "source": [
        "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
        "\n",
        "prompt_template = FewShotPromptTemplate(\n",
        "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
        "    examples=examples,\n",
        "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
        "    input_variables=[\"subject\", \"extra\"],\n",
        "    example_prompt=OPENAI_TEMPLATE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6da3cb",
      "metadata": {
        "id": "fa6da3cb"
      },
      "source": [
        "The `FewShotPromptTemplate` includes:\n",
        "\n",
        "- `prefix` and `suffix`: These likely contain guiding context or instructions.\n",
        "- `examples`: The sample data we defined earlier.\n",
        "- `input_variables`: These variables (\"subject\", \"extra\") are placeholders you can dynamically fill later. For instance, \"subject\" might be filled with \"medical_billing\" to guide the model further.\n",
        "- `example_prompt`: This prompt template is the format we want each example row to take in our prompt.\n",
        "\n",
        "## 4. Creating the Data Generator\n",
        "With the schema and the prompt ready, the next step is to create the data generator. This object knows how to communicate with the underlying language model to get synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "KJqowngfjORP"
      },
      "id": "KJqowngfjORP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9ba911",
      "metadata": {
        "id": "1b9ba911"
      },
      "outputs": [],
      "source": [
        "\n",
        "synthetic_data_generator = create_openai_data_generator(\n",
        "    output_schema=BankingProductPropensity,\n",
        "    llm=ChatOpenAI(\n",
        "        temperature=1\n",
        "    ),  # You'll need to replace with your actual Language Model instance\n",
        "    prompt=prompt_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4198bd6",
      "metadata": {
        "id": "a4198bd6"
      },
      "source": [
        "## 5. Generate Synthetic Data\n",
        "Finally, let's get our synthetic data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a424c890",
      "metadata": {
        "id": "a424c890"
      },
      "outputs": [],
      "source": [
        "synthetic_results = synthetic_data_generator.generate(\n",
        "    subject=\"BankingProductPropensity\",\n",
        "    extra=\"The products include CASA, Credit Card, Mortgage, Term Loan. CIF is unique.\",\n",
        "    runs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the synthetic Data"
      ],
      "metadata": {
        "id": "EPgcUdjTlDns"
      },
      "id": "EPgcUdjTlDns"
    },
    {
      "cell_type": "code",
      "source": [
        "#print results generated by the data generator\n",
        "for result in synthetic_results:\n",
        "\n",
        "  print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09sOsVqplGSu",
        "outputId": "b49b715d-2407-4070-92d3-150146356e1c"
      },
      "id": "09sOsVqplGSu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_id=101234 customer_name='Alex Johnson' age=35 employment_status='Employed' annual_income=85000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=102345 customer_name='Maria Garcia' age=28 employment_status='Self-Employed' annual_income=67000.0 credit_score=680 existing_products=['Checking Account'] product_interest='Personal Loan' propensity_score=0.65\n",
            "customer_id=103456 customer_name='David Smith' age=40 employment_status='Unemployed' annual_income=32000.0 credit_score=590 existing_products=['Credit Card', 'Auto Loan'] product_interest='Credit Card Upgrade' propensity_score=0.55\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=102345 customer_name='Maria Garcia' age=28 employment_status='Self-Employed' annual_income=67000.0 credit_score=680 existing_products=['Checking Account'] product_interest='Personal Loan' propensity_score=0.65\n",
            "customer_id=105678 customer_name='John Johnson' age=35 employment_status='Employed' annual_income=75000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=102345 customer_name='Maria Garcia' age=28 employment_status='Self-Employed' annual_income=67000.0 credit_score=680 existing_products=['Checking Account'] product_interest='Personal Loan' propensity_score=0.65\n",
            "customer_id=105678 customer_name='John Johnson' age=35 employment_status='Employed' annual_income=75000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=102345 customer_name='Maria Garcia' age=28 employment_status='Self-Employed' annual_income=67000.0 credit_score=680 existing_products=['Checking Account'] product_interest='Personal Loan' propensity_score=0.65\n",
            "customer_id=105678 customer_name='John Johnson' age=35 employment_status='Employed' annual_income=75000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=102345 customer_name='Maria Garcia' age=28 employment_status='Self-Employed' annual_income=67000.0 credit_score=680 existing_products=['Checking Account'] product_interest='Personal Loan' propensity_score=0.65\n",
            "customer_id=105678 customer_name='John Johnson' age=35 employment_status='Employed' annual_income=75000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=109876 customer_name='Amy Smith' age=32 employment_status='Unemployed' annual_income=45000.0 credit_score=620 existing_products=['Savings Account', 'Credit Card'] product_interest='CASA' propensity_score=0.55\n",
            "customer_id=105678 customer_name='John Johnson' age=35 employment_status='Employed' annual_income=75000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=109876 customer_name='Amy Smith' age=32 employment_status='Unemployed' annual_income=45000.0 credit_score=620 existing_products=['Savings Account', 'Credit Card'] product_interest='CASA' propensity_score=0.55\n",
            "customer_id=105678 customer_name='John Johnson' age=35 employment_status='Employed' annual_income=75000.0 credit_score=720 existing_products=['Savings Account', 'Credit Card'] product_interest='Mortgage' propensity_score=0.75\n",
            "customer_id=104567 customer_name='Sarah Thompson' age=42 employment_status='Employed' annual_income=92000.0 credit_score=760 existing_products=['Savings Account', 'Credit Card', 'Mortgage'] product_interest='Term Loan' propensity_score=0.85\n",
            "customer_id=987654 customer_name='Emily Johnson' age=29 employment_status='Employed' annual_income=55000.0 credit_score=680 existing_products=['Savings Account', 'Mortgage'] product_interest='Term Loan' propensity_score=0.65\n",
            "customer_id=108765 customer_name='David Smith' age=45 employment_status='Self-Employed' annual_income=85000.0 credit_score=740 existing_products=['Savings Account', 'Credit Card'] product_interest='CASA' propensity_score=0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4402e9",
      "metadata": {
        "id": "fa4402e9"
      },
      "source": [
        "This command asks the generator to produce 10 synthetic medical billing records. The results are stored in `synthetic_results`. The output will be a list of the MedicalBilling pydantic models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}